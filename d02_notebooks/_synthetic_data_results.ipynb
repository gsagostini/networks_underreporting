{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403325c9-2660-4ec7-b68e-e8df0af1d00b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../d03_src/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils_data\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils_evaluation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mev\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils_visualization\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mvis\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils_data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../d03_src/')\n",
    "import utils_data as prd\n",
    "import utils_evaluation as ev\n",
    "import utils_visualization as vis\n",
    "from utils import add_trivial_inspections, set_figsize, latex\n",
    "import vars\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Helvetica Light' #comment in case not installed\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4a9a37-3d30-4d80-8ee5-e17660e84c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available number of experiments: 591\n",
      "Will round it to 500 experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir = '/share/garg/gs665/DEPRECATED_networks_underreporting/d05_joboutputs/calibration/'\n",
    "reg = [int(f.split('.')[0].split('-')[1]) for f in os.listdir(f'{dir}regression-psi-all6/nodestats/') if 'csv' in f]\n",
    "homo = [int(f.split('.')[0].split('-')[1]) for f in os.listdir(f'{dir}homogeneous-psi/nodestats/') if 'csv' in f]\n",
    "homo_reg = [int(f.split('.')[0].split('-')[1]) for f in os.listdir(f'{dir}homogeneous-psi-regression-data/nodestats/') if 'csv' in f]\n",
    "\n",
    "reg.sort()\n",
    "homo.sort()\n",
    "homo_reg.sort()\n",
    "\n",
    "common_indices = list(set(homo)&set(reg)&set(homo_reg))\n",
    "print(f'Available number of experiments:', len(common_indices))\n",
    "\n",
    "nearest_hundred = len(common_indices) - len(common_indices)%100\n",
    "print(f'Will round it to {nearest_hundred} experiments')\n",
    "indices_to_use = common_indices[:nearest_hundred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4f953a-9113-4cde-bfa7-b9d7b385b8a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 212,\n",
       " 213,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 418,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 796,\n",
       " 797]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in common_indices:\n",
    "    for dir in ['homogeneous-psi', 'homogeneous-psi-regression-data', 'regression-psi-all6']:\n",
    "        print(f'cp {dir}/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662ed69-6b34-4117-affe-611350ca5e4f",
   "metadata": {},
   "source": [
    "Parameters to be set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696a196-f1e4-44dd-a2c0-abebd3c9c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_job_dir = \"../d05_joboutputs/calibration/\"\n",
    "n_experiments_to_display=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0105cd-6109-46b8-8ed0-6ee7070fb4d4",
   "metadata": {},
   "source": [
    "# Evaluating Calibration on Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65990633-5432-45ad-9459-0085e5284c86",
   "metadata": {},
   "source": [
    "In this notebook we go through the calibration for the real NY graph with $N=2255$ nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52234620-22af-4bc0-a176-3d782ac527e2",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228845f5-c1f1-45be-bd18-22a2c4f97dff",
   "metadata": {},
   "source": [
    "### Chain Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd240de-3a89-45d9-8b2a-7f4e612cb61e",
   "metadata": {},
   "source": [
    "I am running $2$ chains for $N=60,000$ iterations. The first $20,000$ are discarded, and the remaining $40,000$ are thinned with probability $0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558d4d5-8e85-4481-893f-82551f5471ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 2\n",
    "n_iter = 60_000\n",
    "n_burnin = 20_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1e564-68e8-4d12-936f-1117299cf7a5",
   "metadata": {},
   "source": [
    "The $\\vec{\\theta}$ parameters are sampled using the Single-Variable Exchange Algorithm, with Swandseng-Wang sampling to generate an auxiliary variable from the Ising Model. Each auxiliary variable is generated after $50$ iterations. The ground truth $\\vec{A}$ is sampled on a Gibbs routine given $\\vec{T}$ and all other parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507bad3e-64b7-41cd-b6e7-838348eeeb08",
   "metadata": {},
   "source": [
    "### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19bc07-58be-4975-bdd4-f2226442bca2",
   "metadata": {},
   "source": [
    "The prior I am using on $\\theta$ is\n",
    "\n",
    "$$ \\theta_0 \\sim \\mathcal{N}\\left(0.0, 0.50\\right)$$\n",
    "$$ \\theta_1 \\sim \\mathcal{N}\\left(0.1, 0.03\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1a33e-29e5-4118-afb0-9fd8180751f6",
   "metadata": {},
   "source": [
    "For the case where the report rate $\\psi$ is homogenous, I am using a Beta prior:\n",
    "\n",
    "$$\\psi \\sim \\text{Beta}\\left(\\text{mean}=0.6, \\text{strength}=2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd8826-2c62-4b36-8409-5511c0ce5314",
   "metadata": {},
   "source": [
    "For the case where the report rate $\\psi$ is dependent on demographics, I am using the following covariates:\n",
    "\n",
    "\\begin{align*}\n",
    "X_1 &:= \\log(\\text{population})\\\\\n",
    "X_2 &:= \\text{median income}\\\\\n",
    "X_3 &:= \\text{population with at least a bachelor degree }(\\%)\\\\\n",
    "X_4 &:= \\text{non-hispanic population identifying as white alone }(\\%)\\\\\n",
    "X_5 &:= \\text{median age}\\\\\n",
    "X_6 &:= \\text{households occupied by renter }(\\%)\n",
    "\\end{align*}\n",
    "\n",
    "All covariates are standardized. The reporting rate of cbg $i$ is a logistic linear combination of the form:\n",
    "\n",
    "$$ \\psi_i = \\text{logit}^{-1}\\left(\\alpha_0 + \\sum_{k=1}^6\\alpha_k\\cdot X_{ki}\\right)$$\n",
    "\n",
    "The priors used for the regression coefficients are:\n",
    "\n",
    "$$\\alpha_0 \\sim \\mathcal{N}\\left(0, 1.0\\right)$$\n",
    "$$\\alpha_1,\\dots \\alpha_6 \\sim \\mathcal{N}\\left(0, 0.5\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e39f-c376-4ea5-a1f9-5a5d48aaf433",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef880b-7cdb-449c-905e-65aa71adb243",
   "metadata": {},
   "source": [
    "The graph is that of census tracts, with nodes corresponding to zero population nodes and very long edges removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c96b72-c44f-4569-8678-e97590b72ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_gdf, ny_graph, base_gdf = prd.generate_graph_census(census_unit='tracts',\n",
    "                                                       remove_high_degree_nodes=False,\n",
    "                                                       remove_long_edges=True,\n",
    "                                                       remove_parks=False,\n",
    "                                                       remove_zeropop=True)\n",
    "\n",
    "ny_gdf = ny_gdf.to_crs(vars._projected_crs)\n",
    "base_gdf = base_gdf.to_crs(vars._projected_crs)\n",
    "_ = prd.draw_gdf_and_graph(ny_gdf, ny_graph, base_gdf)\n",
    "\n",
    "N = ny_graph.order()\n",
    "print(f'There are {N} nodes in the graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85c554-6ac0-448d-94d4-ad4b4c0668ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_dict = {}\n",
    "summaries_dict = {}\n",
    "nodestats_dict = {}\n",
    "\n",
    "converged_plots_dict = {}\n",
    "converged_summaries_dict = {}\n",
    "converged_nodestats_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581e3eb-66cb-4afe-822f-92caf8d3a31b",
   "metadata": {},
   "source": [
    "## 1. Homogeneous Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3769c3-848c-4455-b171-b77f09a83b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'homogeneous-psi'\n",
    "model_params = ['theta0', 'theta1', 'psi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6ee53-bf43-4f39-ad11-14b6c8b1cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_dict[model], summaries_dict[model], nodestats_dict[model] = ev.get_summary_files(model, calibration_job_dir,\n",
    "                                                                                       ny_gdf=ny_gdf,\n",
    "                                                                                       include_demographics=True,\n",
    "                                                                                       mode='calibration')\n",
    "#Include baseline:\n",
    "nodestats_dict[f'Baseline Model ({model})'] = [add_trivial_inspections(nodestats_df.copy(), ny_graph).assign(inf_psi=1) for nodestats_df in nodestats_dict[model]]\n",
    "for nodestats_df in nodestats_dict[f'Baseline Model ({model})']: nodestats_df['inf_Tprob'] = nodestats_df['inf_Aprob']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc61a2-a583-4653-a1dd-2964b021e3ca",
   "metadata": {},
   "source": [
    "Convergence diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f944a37-eb18-4d48-a6f8-d89d9129207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats = np.array([list(summary.r_hats.values)[:-1] for summary in summaries_dict[model]])\n",
    "converged_rows = list(np.nonzero((rhats < 1.1).sum(axis=1) == len(model_params))[0])\n",
    "\n",
    "converged_plots_dict[model] = [plots_dict[model][i] for i in converged_rows]\n",
    "converged_summaries_dict[model] = [summaries_dict[model][i] for i in converged_rows]\n",
    "converged_nodestats_dict[model] = [nodestats_dict[model][i] for i in converged_rows]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "_ = ax.hist(rhats, label=model_params)\n",
    "_ = ax.set_title(r'$\\hat{R}$ histogram for model parameters')\n",
    "_ = ax.legend()\n",
    "\n",
    "print(f'We have {len(summaries_dict[model])} experiments, out of which {len(converged_summaries_dict[model])} ({len(converged_summaries_dict[model])/len(summaries_dict[model]):.2%} %) converged.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae63de3-cdde-4f55-a070-d8ec6e810b8c",
   "metadata": {},
   "source": [
    "We have the data summaries saved, as well as chain traces and posterior plots. Let's show how a few experiments went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf889900-4241-4922-8545-5a5eba6b0464",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_plots = plots_dict[model]\n",
    "random.shuffle(available_plots)\n",
    "for plot in available_plots[:n_experiments_to_display]:\n",
    "    display(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e61ef-6d5f-4f36-86e8-c0513245f65c",
   "metadata": {},
   "source": [
    "The calibration plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d014f-3c1c-4f86-b861-73a263685bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = ev.evaluate_summaries(summaries_dict[model], param_names=model_params+['A_mean'])\n",
    "fig, Axes = plt.subplots(figsize=(12, 12), ncols=2, nrows=2)\n",
    "for param, ax in  zip(model_params+['A_mean'], Axes.flatten()):\n",
    "    _ = vis.plot_evaluation_scatterplot(df_dict[param], title=latex(param), ax=ax, show=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb7d61-7a8a-473f-b6d0-5585d1332260",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "_ = vis.plot_calibration(summaries_dict[model],\n",
    "                         param_names=model_params,\n",
    "                         title_size=15,\n",
    "                         ticks_size=13,\n",
    "                         xlabel_size=14,\n",
    "                         ylabel_size=14,\n",
    "                         leg_size=13,\n",
    "                         leg_ncols=1,\n",
    "                         title='Homogeneous Reporting Model Calibration\\n',\n",
    "                         ax=ax,show=False)\n",
    "#fig.savefig('../_paper-plots/calibration_homogeneous.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7094684-4cae-4330-a0ce-0254794aeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_list = ev.compute_AUC(nodestats_dict[model],\n",
    "                          real_data=False, use_Aprob=True,\n",
    "                          average_AUCs=False, plot=False, show=True)\n",
    "print('For the under-reporting model')\n",
    "print(f'The AUC is, on average, {np.mean(AUC_list):.2f} with 95% CI ({np.quantile(AUC_list, 0.275):.2f},{np.quantile(AUC_list, 0.975):.2f})')\n",
    "\n",
    "base_AUC_list = ev.compute_AUC(nodestats_dict[f'Baseline Model ({model})'],\n",
    "                               real_data=False, use_Aprob=True,\n",
    "                               average_AUCs=False,\n",
    "                               plot=False, show=True)\n",
    "print('\\nFor the baseline model')\n",
    "print(f'The AUC is, on average, {np.mean(base_AUC_list):.2f} with 95% CI ({np.quantile(base_AUC_list, 0.275):.2f},{np.quantile(base_AUC_list, 0.975):.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9961da0-b2f7-4e34-bfa9-dbc08bb49650",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a3994-1c87-47ee-9e25-5c54e1ab0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'regression-psi-all6'\n",
    "model_params = ['theta0', 'theta1'] + [f'alpha{k}' for k in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379e6c8-0976-4777-ba8b-f247ad9bc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_dict[model], summaries_dict[model], nodestats_dict[model] = ev.get_summary_files(model, calibration_job_dir,\n",
    "                                                                                       ny_gdf=ny_gdf,\n",
    "                                                                                       include_demographics=True,\n",
    "                                                                                       mode='calibration')\n",
    "#Include baseline:\n",
    "nodestats_dict[f'Baseline Model ({model})'] = [add_trivial_inspections(nodestats_df.copy(), ny_graph).assign(inf_psi=1) for nodestats_df in nodestats_dict[model]]\n",
    "for nodestats_df in nodestats_dict[f'Baseline Model ({model})']: nodestats_df['inf_Tprob'] = nodestats_df['inf_Aprob']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed50e11-7702-420d-ad90-aec0e9cd149d",
   "metadata": {},
   "source": [
    "Convergence diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebc897-9960-416a-acf7-3ba8d26a0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats = np.array([list(summary.r_hats.values)[:-1] for summary in summaries_dict[model]])\n",
    "converged_rows = list(np.nonzero((rhats < 1.1).sum(axis=1) == len(model_params))[0])\n",
    "\n",
    "converged_plots_dict[model] = [plots_dict[model][i] for i in converged_rows]\n",
    "converged_summaries_dict[model] = [summaries_dict[model][i] for i in converged_rows]\n",
    "converged_nodestats_dict[model] = [nodestats_dict[model][i] for i in converged_rows]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "_ = ax.hist(rhats, label=model_params)\n",
    "_ = ax.set_title(r'$\\hat{R}$ histogram for model parameters')\n",
    "_ = ax.legend()\n",
    "\n",
    "print(f'We have {len(summaries_dict[model])} experiments, out of which {len(converged_summaries_dict[model])} ({len(converged_summaries_dict[model])/len(summaries_dict[model]):.2%} %) converged.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82af5e-c210-4297-84c6-90674b6681e4",
   "metadata": {},
   "source": [
    "We have the data summaries saved, as well as chain traces and posterior plots. Let's show how a few experiments went:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6b273-9765-47f6-9481-173c3a71ce6d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_plots = plots_dict[model]\n",
    "random.shuffle(available_plots)\n",
    "for plot in available_plots[:n_experiments_to_display]:\n",
    "    display(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49867602-2f6d-4bb4-ade9-ab6da61fa27c",
   "metadata": {},
   "source": [
    "The calibration plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1533b-9a23-4171-8dad-9c334abda50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = ev.evaluate_summaries(summaries_dict[model], param_names=model_params+['A_mean'])\n",
    "fig, Axes = plt.subplots(figsize=(18, 18), ncols=3, nrows=3)\n",
    "for idx, (param, ax) in  enumerate(zip(model_params+['A_mean'], Axes.flatten())):\n",
    "    _ = vis.plot_evaluation_scatterplot(df_dict[param],\n",
    "                                        title=latex(param),\n",
    "                                        ax=ax, show=False,\n",
    "                                        ylabel='Posterior mean' if idx==3 else None,\n",
    "                                        xlabel='True parameter' if idx==7 else None)\n",
    "\n",
    "plt.savefig('../_paper-plots/calibration_heterogeneous_scatterplot_full.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfd6f8-e05d-4933-905a-557b542725ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "_ = vis.plot_calibration(summaries_dict[model],\n",
    "                         param_names=model_params,\n",
    "                         title_size=15,\n",
    "                         ticks_size=13,\n",
    "                         xlabel_size=14,\n",
    "                         ylabel_size=14,\n",
    "                         leg_size=13,\n",
    "                         leg_ncols=1,\n",
    "                         title='Heterogeneous Reporting Model Calibration\\n',\n",
    "                         ax=ax,show=False)\n",
    "plt.savefig('../_paper-plots/calibration_heterogeneous.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67359260-9861-4cb2-92ef-fd560296a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, Axes = plt.subplots(figsize=(12,6), ncols=2)\n",
    "\n",
    "_ = vis.plot_calibration(summaries_dict['homogeneous-psi'],\n",
    "                         param_names=['theta0', 'theta1', 'psi'],\n",
    "                         title_size=15,\n",
    "                         ticks_size=13,\n",
    "                         xlabel_size=14,\n",
    "                         xlabel=None,\n",
    "                         ylabel_size=14,\n",
    "                         leg_size=13,\n",
    "                         leg_ncols=1,\n",
    "                         title='Homogeneous Reporting Model\\n',\n",
    "                         ax=Axes[0],show=False)\n",
    "\n",
    "_ = vis.plot_calibration(summaries_dict[model],\n",
    "                         param_names=model_params,\n",
    "                         title_size=15,\n",
    "                         ticks_size=13,\n",
    "                         xlabel_size=14,\n",
    "                         ylabel=None,\n",
    "                         ylabel_size=14,\n",
    "                         leg_size=13,\n",
    "                         leg_ncols=1,\n",
    "                         title='Heterogeneous Reporting Model\\n',\n",
    "                         ax=Axes[1],show=False)\n",
    "plt.savefig('../_paper-plots/calibration_maintext.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad48d9-3288-4c9f-8363-242fb06e93e3",
   "metadata": {},
   "source": [
    "For the paper we will put them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c20c7-8e38-4f86-ac83-4c90cf914071",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, Axes = plt.subplots(figsize=(10, 10), ncols=2, nrows=2)\n",
    "\n",
    "params_to_plot = ['theta0', 'alpha0', 'alpha2', 'alpha4']\n",
    "params_to_plot_annot = ['(flood prevalence)', '(intercept)', '(median income)', '(white population)']\n",
    "for idx, (param, ax) in enumerate(zip(params_to_plot, Axes.flatten())): #2: median income and 4: race white\n",
    "    _ = vis.plot_evaluation_scatterplot(df_dict[param],\n",
    "                                        title=latex(param) +' '+params_to_plot_annot[idx],\n",
    "                                        ylabel = 'Posterior mean' if idx in [0,2] else None,\n",
    "                                        xlabel = 'True parameter' if idx in [2,3] else None,\n",
    "                                        correlation_size=10,\n",
    "                                        ax=ax, show=False)\n",
    "plt.savefig('../_paper-plots/calibration_heterogeneous_scatterplot_maintext.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d01673-ccc7-4147-8507-00b08c148cea",
   "metadata": {},
   "source": [
    "AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd4341-31c0-4285-90fa-f62059ebd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_list = ev.compute_AUC(nodestats_dict[model],\n",
    "                          real_data=False, use_Aprob=True,\n",
    "                          average_AUCs=False, plot=False, show=True)\n",
    "print('For the heterogeneous reporting model')\n",
    "print(f'The AUC is, on average, {np.mean(AUC_list):.2f} with 95% CI ({np.quantile(AUC_list, 0.275):.2f},{np.quantile(AUC_list, 0.975):.2f})')\n",
    "\n",
    "base_AUC_list = ev.compute_AUC(nodestats_dict[f'Baseline Model ({model})'],\n",
    "                               real_data=False, use_Aprob=True,\n",
    "                               average_AUCs=False,\n",
    "                               plot=False, show=True)\n",
    "print('\\nFor the baseline model')\n",
    "print(f'The AUC is, on average, {np.mean(base_AUC_list):.2f} with 95% CI ({np.quantile(base_AUC_list, 0.275):.2f},{np.quantile(base_AUC_list, 0.975):.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22650667-5d4c-442c-b9c5-162474243d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
